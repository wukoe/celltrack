{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wb/apps/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load and process data\n",
    "import os,gc\n",
    "from importlib import reload\n",
    "import torch\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from model_args import aot_args,sam_args,segtracker_args\n",
    "\n",
    "from wbtool.show import wshow\n",
    "from wbtool import file_misc as fm\n",
    "from wbtool import use_models\n",
    "import proc_data\n",
    "\n",
    "\n",
    "vid = np.load('/home/wb/samba_dir/cells_brightfield/leadingcell-WB-entirespan/B1ROI1.npy')\n",
    "vid = proc_data.value_modify(vid)\n",
    "\n",
    "ids,coords = proc_data.read_coords_from_csv('/home/wb/samba_dir/cells_brightfield/leadingcell-WB-entirespan/Results_B1ROI1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(show)\n",
    "fid = 20\n",
    "point_prompt = coords[fid]\n",
    "obj_mode = np.ones((len(point_prompt), 1))\n",
    "frame = vid[fid]\n",
    "frame = proc_data.value_modify(frame)\n",
    "print(frame.shape)\n",
    "\n",
    "show.overlay_point(frame, point_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sam_checkpoint': '/home/wb/wb_data/model_parameter_storage/SAM/sam_vit_h_4b8939.pth', 'model_type': 'vit_h', 'generator_args': {'points_per_side': 16, 'pred_iou_thresh': 0.8, 'stability_score_thresh': 0.9, 'crop_n_layers': 1, 'crop_n_points_downscale_factor': 2, 'min_mask_region_area': 200}, 'gpu_id': 0}\n"
     ]
    }
   ],
   "source": [
    "import SegTracker\n",
    "from model_args import aot_args,sam_args,segtracker_args\n",
    "# import SegTracker #import SegTracker\n",
    "# importlib.reload(SegTracker)\n",
    "print(sam_args)\n",
    "sam_args['generator_args'] = {\n",
    "        'points_per_side': 30,\n",
    "        'pred_iou_thresh': 0.8,\n",
    "        'stability_score_thresh': 0.9,\n",
    "        'crop_n_layers': 1,\n",
    "        'crop_n_points_downscale_factor': 2,\n",
    "        'min_mask_region_area': 200,\n",
    "    }\n",
    "\n",
    "# segtracker = SegTracker.SegTracker(segtracker_args,sam_args,aot_args)\n",
    "SA = use_models.cv.sam_agent('prompt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment for frame 1\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m frame \u001b[38;5;241m=\u001b[39m proc_data\u001b[38;5;241m.\u001b[39mvalue_modify(frame)\n\u001b[1;32m     41\u001b[0m ms \u001b[38;5;241m=\u001b[39m SA\u001b[38;5;241m.\u001b[39minfer(frame, point_prompt)\n\u001b[0;32m---> 42\u001b[0m ms \u001b[38;5;241m=\u001b[39m \u001b[43mproc_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_mask_by_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegtracker_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_obj_area_ratio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegtracker_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_obj_area_ratio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m ms \u001b[38;5;241m=\u001b[39m morph_proc\u001b[38;5;241m.\u001b[39mmasks_to_map(ms)\n\u001b[1;32m     44\u001b[0m ms \u001b[38;5;241m=\u001b[39m ovmorph\u001b[38;5;241m.\u001b[39misolate_object(ms, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/disk_c/data_transfer/samba/indev/celltrack/proc_data.py:34\u001b[0m, in \u001b[0;36mfilter_mask_by_size\u001b[0;34m(masks, lb, hb)\u001b[0m\n\u001b[1;32m     32\u001b[0m mar \u001b[38;5;241m=\u001b[39m ma\u001b[38;5;241m/\u001b[39mimga\n\u001b[1;32m     33\u001b[0m I \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbitwise_and(mar\u001b[38;5;241m<\u001b[39mhb, mar\u001b[38;5;241m>\u001b[39mlb)\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mI\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Generate Results for the Whole Video\n",
    "from skimage import morphology\n",
    "from onevision import morphology as ovmorph\n",
    "from onevision import morph_proc\n",
    "import aux\n",
    "# reload(proc_data)\n",
    "# reload(ovmorph)\n",
    "\n",
    "segtracker_args = {\n",
    "    'sam_gap': 1, # the interval to run sam to segment new objects\n",
    "    'min_area': 20, # minimal mask area to add a new mask as a new object\n",
    "    'max_obj_num': 255, # maximal object number to track in a video\n",
    "    'min_new_obj_iou': 0.8, # the area of a new object in the background should > 80% \n",
    "    'new_replace_iou_min': 0.5,\n",
    "    'remain_remove_max':0.4,\n",
    "    'min_obj_area_ratio':0.0001,\n",
    "    'max_obj_area_ratio':0.01\n",
    "}\n",
    "\n",
    "# output masks\n",
    "output_dir = '/home/wb/samba_dir/indev/results' #io_args['output_mask_dir']\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# grounding_caption = \"cell\"\n",
    "# box_threshold, text_threshold, box_size_threshold, reset_image = 0.02, 0.02, 0.05, True\n",
    "\n",
    "fnum = len(vid)\n",
    "sz = vid[0].shape\n",
    "frame_area = sz[0] * sz[1]\n",
    "\n",
    "# === get segmentation results of each frame.\n",
    "# (this is independent of tracking activity)\n",
    "seg_list = []\n",
    "for frame_idx in range(fnum):\n",
    "    point_prompt = coords[frame_idx]\n",
    "    # obj_mode = np.ones((len(point_prompt), 1))\n",
    "    frame = vid[frame_idx]\n",
    "    frame = proc_data.value_modify(frame)\n",
    "    \n",
    "    ms = SA.infer(frame, point_prompt)\n",
    "    ms = proc_data.filter_mask_by_size(ms, segtracker_args['min_obj_area_ratio'], segtracker_args['max_obj_area_ratio'])\n",
    "    ms = morph_proc.masks_to_map(ms)\n",
    "    ms = ovmorph.isolate_object(ms, False)\n",
    "    pred_mask = ovmorph.filter_object_size(ms, segtracker_args['min_obj_area_ratio'], segtracker_args['max_obj_area_ratio'])\n",
    "    seg_list.append(pred_mask)\n",
    "    print(\"segment for frame {}\".format(frame_idx), end='\\r')\n",
    "\n",
    "# 对于第一个segment map，将ID连续分布，因为其作为tracking的起点。\n",
    "seg_list[0] = morph_proc.id_reset(seg_list[0])\n",
    "print('\\n-segmentation done')\n",
    "\n",
    "# === tracking\n",
    "segtracker = SegTracker.SegTracker(segtracker_args,sam_args,aot_args)\n",
    "segtracker.restart_tracker()   # 调用的是aot_tracker/AOTTracker function, AOT模型自身的restart要求.\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# tms,sms,nobs=[],[],[]\n",
    "# with torch.cuda.amp.autocast():\n",
    "for frame_idx in range(fnum):\n",
    "    frame = vid[frame_idx]\n",
    "    frame = proc_data.value_modify(frame)\n",
    "\n",
    "    if frame_idx == 0:\n",
    "        # print(segtracker.curr_idx)\n",
    "        pred_mask = seg_list[frame_idx]\n",
    "        segtracker.add_reference(frame, pred_mask)\n",
    "    elif (frame_idx % segtracker_args['sam_gap']) == 0:\n",
    "        # 1/2\n",
    "        seg_mask = seg_list[frame_idx]\n",
    "        # 2/2\n",
    "        # seg_mask,_ = segtracker.detect_and_seg(frame, grounding_caption, box_threshold, text_threshold, box_size_threshold, reset_image)\n",
    "        # e/2\n",
    "\n",
    "        # torch.cuda.empty_cache()\n",
    "        # gc.collect()\n",
    "        track_mask = segtracker.track(frame)\n",
    "        idmax = track_mask.max()\n",
    "        track_mask = ovmorph.isolate_object(track_mask)\n",
    "        track_mask = ovmorph.filter_object_size(track_mask, segtracker_args['min_obj_area_ratio'], segtracker_args['max_obj_area_ratio'])\n",
    "        # 对于新增加物体，将ID重整成连续分布\n",
    "        ids = np.unique(track_mask)\n",
    "        if ids.max() > idmax:  #若确实发生了id数量增加\n",
    "            ids = ids[ids!=0]\n",
    "            id_groups = [ids[ids<=idmax], ids[ids>idmax]]\n",
    "            if id_groups[1].max() > (id_groups[0].max() + len(id_groups[1])):  #若确实出现不连续分布的情况\n",
    "                temp = morph_proc.split_map(track_mask, id_groups)\n",
    "                temp[1] = morph_proc.id_reset(temp[1], base=idmax+1)\n",
    "                track_mask = temp[0] + temp[1]\n",
    "\n",
    "        # find new objects, and update tracker with new objects\n",
    "        # 1/2\n",
    "        # new_obj_mask = aux.find_new_objs(segtracker_args, track_mask, seg_mask, segtracker.curr_idx)\n",
    "        # 2/2\n",
    "        new_obj_mask = seg_mask\n",
    "        # e/2\n",
    "        \n",
    "        # merge tracking and new segment maps.\n",
    "        # 1/2\n",
    "        # pred_mask = track_mask + new_obj_mask\n",
    "        # 2/2\n",
    "        pred_mask = aux.merge_st(segtracker_args, track_mask, new_obj_mask)\n",
    "        # e/2\n",
    "\n",
    "        # segtracker.restart_tracker()\n",
    "        segtracker.add_reference(frame, pred_mask)\n",
    "    else:\n",
    "        pred_mask = segtracker.track(frame, update_memory=True)\n",
    "    # gc.collect()\n",
    "    proc_data.save_prediction(pred_mask, output_dir, str(frame_idx)+'.png')    \n",
    "    print(\"processed frame {}, obj_num {}\".format(frame_idx, segtracker.get_obj_num()), end='\\r')\n",
    "\n",
    "print('\\n-finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sr[3].shape)\n",
    "X = [merge_mask(it) for it in sr]\n",
    "\n",
    "print([it.max() for it in X])\n",
    "show.wshow(X[3])\n",
    "show.wshow(X[4])\n",
    "# # print(sum(sum(sr[0])))\n",
    "# # print(sum(sum(sr[4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "供参考的SegTracker函数\n",
    "\n",
    "刘平版：\n",
    "def detect_and_seg_pt(self, origin_frame: np.ndarray, coords, modes):\n",
    "    '''\n",
    "    Using Grounding-DINO to detect object acc Text-prompts\n",
    "    Retrun:\n",
    "        refined_merged_mask: numpy array (h, w)\n",
    "        annotated_frame: numpy array (h, w, 3)\n",
    "    '''\n",
    "            # backup id and origin-merged-mask\n",
    "    bc_id = self.curr_idx\n",
    "    bc_mask = self.origin_merged_mask\n",
    "    \n",
    "    # get annotated_frame and boxes\n",
    "    # annotated_frame, boxes = self.detector.run_grounding(origin_frame, grounding_caption, box_threshold, text_threshold)\n",
    "    for i in range(len(coords)):\n",
    "        pt = coords[i].reshape([1,2])\n",
    "        mode = modes[i]\n",
    "        # if (bbox[1][0] - bbox[0][0]) * (bbox[1][1] - bbox[0][1]) > annotated_frame.shape[0] * annotated_frame.shape[1] * box_size_threshold:\n",
    "        #     continue\n",
    "        interactive_mask = self.sam.segment_with_click(origin_frame, pt, mode)\n",
    "\n",
    "        mask = interactive_mask.copy()\n",
    "        if(mask.sum(1).sum(0)/(mask.shape[0]*mask.shape[1]) < 0.01): \n",
    "            refined_merged_mask = self.add_mask(interactive_mask)\n",
    "            self.update_origin_merged_mask(refined_merged_mask)\n",
    "            self.curr_idx += 1\n",
    "\n",
    "    # reset origin_mask\n",
    "    self.reset_origin_merged_mask(bc_mask, bc_id)\n",
    "\n",
    "    return refined_merged_mask\n",
    "\n",
    "最终版：\n",
    "    def detect_and_seg_pt(self, frame: np.ndarray, coords, modes):\n",
    "        '''\n",
    "        Using Grounding-DINO to detect object acc Text-prompts\n",
    "        Retrun:\n",
    "            refined_merged_mask: numpy array (h, w)\n",
    "            annotated_frame: numpy array (h, w, 3)\n",
    "        '''\n",
    "        # backup id and origin-merged-mask\n",
    "        bc_id = self.curr_idx\n",
    "        bc_mask = self.origin_merged_mask\n",
    "    \n",
    "        # get annotated_frame and boxes\n",
    "        # annotated_frame, boxes = self.detector.run_grounding(frame, grounding_caption, box_threshold, text_threshold)\n",
    "        cnum = len(coords)\n",
    "        imgarea = frame.shape[0]*frame.shape[1]\n",
    "        # ims = []\n",
    "        refined_merged_mask = self.add_mask(np.zeros(frame.shape[:2], dtype=np.uint8))\n",
    "        for k in range(cnum):\n",
    "            # if (bbox[1][0] - bbox[0][0]) * (bbox[1][1] - bbox[0][1]) > annotated_frame.shape[0] * annotated_frame.shape[1] * box_size_threshold:\n",
    "            #     continue\n",
    "            interactive_mask = self.sam.segment_with_click(frame, coords[k:k+1], modes[k], True)\n",
    "            # ims.append(interactive_mask.copy())\n",
    "            \n",
    "            if interactive_mask.sum(1).sum(0)/imgarea < 0.01:\n",
    "                refined_merged_mask = self.add_mask(interactive_mask)  #在self.origin_merged_mask 的基础上，根据输入修改得到返回值。\n",
    "                self.update_origin_merged_mask(refined_merged_mask)\n",
    "                self.curr_idx += 1\n",
    "\n",
    "        # reset origin_mask\n",
    "        self.reset_origin_merged_mask(bc_mask, bc_id)\n",
    "\n",
    "        return refined_merged_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
